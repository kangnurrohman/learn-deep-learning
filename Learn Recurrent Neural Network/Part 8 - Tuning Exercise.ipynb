{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kangnurrohman/belajar-recurrent-neural-network/blob/main/materi/Part%208%20-%20Tuning%20Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rO4t4en-U_eL",
        "outputId": "1c4c8526-1773-40cd-e8be-f2669228377d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rO4t4en-U_eL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/data/data 4.zip\", 'r')\n",
        "zip_ref.extractall(\"data\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "bv9l-JG6VCe5"
      },
      "id": "bv9l-JG6VCe5",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faeddb24",
      "metadata": {
        "id": "faeddb24"
      },
      "outputs": [],
      "source": [
        "pip install jcopdl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jcopdl.callback import set_config"
      ],
      "metadata": {
        "id": "jw9HkXnfUGGt"
      },
      "id": "jw9HkXnfUGGt",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"damped_sine\"\n",
        "# data = \"jkse\"\n",
        "\n",
        "config = set_config({\n",
        "    \"input_size\": 1,\n",
        "    \"seq_len\": 0,\n",
        "    \"batch_size\": 0,\n",
        "    \"output_size\": 1,\n",
        "    \"hidden_size\": 0,\n",
        "    \"num_layers\": 0,\n",
        "    \"dropout\": 0.,\n",
        "    \"bidirectional\": \"____\", # True/False\n",
        "    \"cell_type\": \"____\" # rnn/gru/lstm\n",
        "})\n",
        "\n",
        "lr = \"_____\""
      ],
      "metadata": {
        "id": "9bNL8e5BUGjC"
      },
      "id": "9bNL8e5BUGjC",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Don't edit this code**"
      ],
      "metadata": {
        "id": "MzfIIeYHUL9N"
      },
      "id": "MzfIIeYHUL9N"
    },
    {
      "cell_type": "code",
      "source": [
        "# utils\n",
        "def data4pred(model, dataset, dataloader, device):    \n",
        "    preds, targets = [], []\n",
        "    hidden = None\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for inputs, target in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            \n",
        "            output, hidden = model(inputs, hidden)\n",
        "            preds += output.flatten().tolist()\n",
        "            targets += target.flatten().tolist()\n",
        "\n",
        "    plt.plot(dataset.target_ticks, targets, 'b-', label=\"data\")\n",
        "    plt.plot(dataset.target_ticks, preds, 'r-', label=\"pred\")\n",
        "    plt.legend()    \n",
        "    \n",
        "def pred4pred(model, dataset, dataloader, device, n_prior=500, n_forecast=200):\n",
        "    preds, targets = [], []\n",
        "    hidden = None    \n",
        "    end = n_prior + n_forecast    \n",
        "    with torch.no_grad():\n",
        "        model.eval()       \n",
        "        for idx, (inputs, target) in enumerate(dataloader):\n",
        "            if idx == end:\n",
        "                break\n",
        "            elif idx > n_prior:\n",
        "                inputs[0, 0, 0] = preds[-1]\n",
        "                \n",
        "            inputs = inputs.to(device)\n",
        "            output, hidden = model(inputs, hidden)\n",
        "            \n",
        "            if idx > n_prior:\n",
        "                preds.append(output.flatten().tolist()[-1])\n",
        "            else:\n",
        "                preds += output.flatten().tolist()   \n",
        "            targets += target.flatten().tolist()\n",
        "\n",
        "    plt.plot(dataset.target_ticks[:n_prior], targets[:n_prior], 'b-', label=\"history_data\")\n",
        "    plt.plot(dataset.target_ticks[n_prior:end], targets[n_prior:], 'b-', label=\"unseen_data\", alpha=0.3)\n",
        "    plt.plot(dataset.target_ticks[:end], preds, 'r-', label=\"prediction\")\n",
        "    plt.axvline(dataset.target_ticks[n_prior], color='k', linestyle=\"--\", linewidth=1)\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "g0o7zFgVUoPk"
      },
      "id": "g0o7zFgVUoPk",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from jcopdl.callback import Callback\n",
        "from jcopdl.utils.dataloader import TimeSeriesDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, cell_type, input_size, output_size, hidden_size, num_layers, dropout, bidirectional):\n",
        "        super().__init__()\n",
        "        \n",
        "        if cell_type == \"rnn\":\n",
        "            rnn_block = nn.RNN\n",
        "        elif cell_type == \"lstm\":\n",
        "            rnn_block = nn.LSTM\n",
        "        elif cell_type == \"gru\":\n",
        "            rnn_block = nn.GRU\n",
        "        \n",
        "        self.rnn = rnn_block(input_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
        "        \n",
        "        if bidirectional:\n",
        "            hidden_size = 2*hidden_size\n",
        "            \n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x, hidden):        \n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        x = self.fc(x)\n",
        "        return x, hidden\n",
        "    \n",
        "if data == \"damped_sine\":\n",
        "    df = pd.read_csv(\"/content/data/sine_new.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "    df.value = df.value.transform(lambda x: (x-x.mean())/x.std())\n",
        "    col = \"value\"    \n",
        "elif data == \"jkse\":\n",
        "    df = pd.read_csv(\"/content/data/jkse.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "    df = df[~df.price.isna()]\n",
        "    df.price = df.price.transform(lambda x: (x-x.mean())/x.std())\n",
        "    col = \"price\"\n",
        "\n",
        "ts_train, ts_test = train_test_split(df, test_size=0.2, shuffle=False)\n",
        "\n",
        "train_set = TimeSeriesDataset(ts_train, col, config.seq_len)\n",
        "trainloader = DataLoader(train_set, batch_size=config.batch_size)\n",
        "\n",
        "test_set = TimeSeriesDataset(ts_test, col, config.seq_len)\n",
        "testloader = DataLoader(test_set, batch_size=config.batch_size)\n",
        "\n",
        "model = RNN(config.cell_type, config.input_size, config.output_size, config.hidden_size, \n",
        "            config.num_layers, config.dropout, config.bidirectional).to(device)\n",
        "criterion = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "callback = Callback(model, config, outdir=f'model/{data}/')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n",
        "    if mode == \"train\":\n",
        "        model.train()\n",
        "    elif mode == \"test\":\n",
        "        model.eval()\n",
        "    cost = 0\n",
        "    for feature, target in tqdm(dataloader, desc=mode.title()):\n",
        "        feature, target = feature.to(device), target.to(device)\n",
        "        output, hidden = model(feature, None)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        if mode == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        cost += loss.item() * feature.shape[0]\n",
        "    cost = cost / len(dataset)\n",
        "    return cost\n",
        "\n",
        "while True:\n",
        "    train_cost = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device)\n",
        "    with torch.no_grad():\n",
        "        test_cost = loop_fn(\"test\", test_set, testloader, model, criterion, optimizer, device)\n",
        "    \n",
        "    # Logging\n",
        "    callback.log(train_cost, test_cost)\n",
        "\n",
        "    # Checkpoint\n",
        "    callback.save_checkpoint()\n",
        "        \n",
        "    # Runtime Plotting\n",
        "    callback.cost_runtime_plotting()\n",
        "    \n",
        "    # Early Stopping\n",
        "    if callback.early_stopping(model, monitor=\"test_cost\"):\n",
        "        callback.plot_cost()\n",
        "        break\n",
        "        \n",
        "# Forecast\n",
        "train_forecast_set = TimeSeriesDataset(ts_train, col, 1)\n",
        "trainforecastloader = DataLoader(train_forecast_set)\n",
        "\n",
        "test_forecast_set = TimeSeriesDataset(ts_test, col, 1)\n",
        "testforecastloader = DataLoader(test_forecast_set)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "    \n",
        "plt.subplot(311)\n",
        "data4pred(model, train_forecast_set, trainforecastloader, device)\n",
        "plt.title(\"Train\")\n",
        "\n",
        "plt.subplot(312)\n",
        "data4pred(model, test_forecast_set, testforecastloader, device)\n",
        "plt.title(\"Test\")\n",
        "\n",
        "plt.subplot(313)\n",
        "pred4pred(model, test_forecast_set, testforecastloader, device, n_prior=400, n_forecast=100)\n",
        "plt.title(\"Test\")"
      ],
      "metadata": {
        "id": "rixyIjqXULCi"
      },
      "id": "rixyIjqXULCi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}